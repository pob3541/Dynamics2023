{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# THIS CELL SETS STUFF UP FOR DEMO / COLLAB. THIS CELL CAN BE IGNORED.\n",
    "\n",
    "#-------------------------------------GET RID OF TF DEPRECATION WARNINGS--------------------------------------#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "#----------------------------------INSTALL PSYCHRNN IF IN A COLAB NOTEBOOK-------------------------------------#\n",
    "# Installs the correct branch / release version based on the URL. If no branch is provided, loads from master.\n",
    "# Loads saved weights from correct branch and saves a local copy for later use.\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import json\n",
    "    import re\n",
    "    import ipykernel\n",
    "    import requests \n",
    "    from requests.compat import urljoin\n",
    "    from io import BytesIO\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    from notebook.notebookapp import list_running_servers\n",
    "    kernel_id = re.search('kernel-(.*).json',\n",
    "                          ipykernel.connect.get_connection_file()).group(1)\n",
    "    servers = list_running_servers()\n",
    "    for ss in servers:\n",
    "        response = requests.get(urljoin(ss['url'], 'api/sessions'),\n",
    "                                params={'token': ss.get('token', '')})\n",
    "        for nn in json.loads(response.text):\n",
    "            if nn['kernel']['id'] == kernel_id:\n",
    "                relative_path = nn['notebook']['path'].split('%2F')\n",
    "                if 'blob' in relative_path:\n",
    "                  blob = relative_path[relative_path.index('blob') + 1]\n",
    "                  !pip install git+https://github.com/murraylab/PsychRNN@$blob\n",
    "                  file_location = \"https://github.com/murraylab/PsychRNN/blob/\" + blob + \"/docs/notebooks/weights/saved_weights.npz?raw=true\"\n",
    "                else:\n",
    "                  !pip install git+https://github.com/murraylab/PsychRNN\n",
    "                  file_location = \"https://github.com/murraylab/PsychRNN/docs/notebooks/weights/saved_weights.npz?raw=true\"\n",
    "\n",
    "    r = requests.get(file_location, stream = True)\n",
    "    data = dict(np.load(BytesIO(r.raw.read()), allow_pickle = True))\n",
    "    if not os.path.exists(\"./weights\"):\n",
    "        os.makedirs(\"./weights\")\n",
    "    np.savez(\"./weights/saved_weights.npz\", **data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and Modifying Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Simple Example](PerceptualDiscrimination.ipynb#Get-&-Save-Model-Weights), we saved weights to ``./weights/saved_weights``. Here we will load those weights, and modify them by silencing a few recurrent units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = dict(np.load('./weights/saved_weights.npz', allow_pickle = True))\n",
    "weights['W_rec'][:10, :10] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the different weights you have access to for modifying. The ones that don't end in ``Adam`` or ``Adam_1`` will be read in when loading a model from weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['init_state', 'W_in', 'W_rec', 'W_out', 'b_rec', 'b_out', 'Dale_rec', 'Dale_out', 'input_connectivity', 'rec_connectivity', 'output_connectivity', 'init_state/Adam', 'init_state/Adam_1', 'W_in/Adam', 'W_in/Adam_1', 'W_rec/Adam', 'W_rec/Adam_1', 'W_out/Adam', 'W_out/Adam_1', 'b_rec/Adam', 'b_rec/Adam_1', 'b_out/Adam', 'b_out/Adam_1', 'dale_ratio'])\n"
     ]
    }
   ],
   "source": [
    "print(weights.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the modified weights at ``'./weights/modified_saved_weights.npz'``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./weights/modified_saved_weights.npz', **weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model with Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psychrnn.backend.models.basic import Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {'N_batch': 50,\n",
    "                  'N_in': 2,\n",
    "                  'N_out': 2,\n",
    "                  'dt': 10,\n",
    "                  'tau': 100,\n",
    "                  'T': 2000,\n",
    "                  'N_steps': 200,\n",
    "                  'N_rec': 50\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_network_params = network_params.copy()\n",
    "file_network_params['name'] = 'file'\n",
    "file_network_params['load_weights_path'] = './weights/modified_saved_weights.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileModel = Basic(file_network_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the W_rec weights are modified as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(fileModel.get_weights()['W_rec'][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileModel.destruct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from Weights Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_network_params = network_params.copy()\n",
    "dict_network_params['name'] = 'dict'\n",
    "dict_network_params.update(weights)\n",
    "type(dict_network_params['dale_ratio']) == np.ndarray and dict_network_params['dale_ratio'].item() is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel = Basic(dict_network_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the W_rec weights are modified as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(dictModel.get_weights()['W_rec'][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictModel.destruct()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
